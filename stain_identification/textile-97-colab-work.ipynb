{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Unblanced data \n",
    "\n",
    "\n",
    "i had to balance the data so here you could find new data and colab notebook  \n",
    "\n",
    "\n",
    " colab : [colab.research.google.com/drive/141XZ18NzQHcgkV1BAceFY43m9q6lveSv?usp=sharing](http://)\n",
    " \n",
    " newdata : https://drive.google.com/drive/folders/1lV_LIy2XPnIHC5Kcd_d4PsE8sNs434U6?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nMxRR4NofcCu",
    "ExecuteTime": {
     "start_time": "2023-03-31T00:56:40.629952Z",
     "end_time": "2023-03-31T00:56:44.724379Z"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries \n",
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds\n",
    "import keras \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "from keras.applications import VGG19,Xception,VGG16\n",
    "from keras.layers import Dense , Conv2D , MaxPooling2D , Dropout,Flatten,Convolution2D\n",
    "from keras.models  import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JWzjQnsd3D4l",
    "outputId": "b0ac138b-a6cb-4619-e124-8e4e685dde44"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#access my drive\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      3\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#access my drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lrETnx-33GOe",
    "outputId": "9675b8c1-955e-4db2-e2ea-ad316656f674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "303128576/574710816 [==============>...............] - ETA: 2:04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#call vgg model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m vgg_model \u001B[38;5;241m=\u001B[39m  \u001B[43mVGG19\u001B[49m\u001B[43m(\u001B[49m\u001B[43minclude_top\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimagenet\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m models \u001B[38;5;129;01min\u001B[39;00m vgg_model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m      4\u001B[0m   models\u001B[38;5;241m.\u001B[39mtrainable\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\applications\\vgg19.py:243\u001B[0m, in \u001B[0;36mVGG19\u001B[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001B[0m\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimagenet\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m include_top:\n\u001B[1;32m--> 243\u001B[0m         weights_path \u001B[38;5;241m=\u001B[39m \u001B[43mdata_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    244\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvgg19_weights_tf_dim_ordering_tf_kernels.h5\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    245\u001B[0m \u001B[43m            \u001B[49m\u001B[43mWEIGHTS_PATH\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    246\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_subdir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    247\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfile_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcbe5617147190e668d6c5d5026f83318\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    248\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    250\u001B[0m         weights_path \u001B[38;5;241m=\u001B[39m data_utils\u001B[38;5;241m.\u001B[39mget_file(\n\u001B[0;32m    251\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    252\u001B[0m             WEIGHTS_PATH_NO_TOP,\n\u001B[0;32m    253\u001B[0m             cache_subdir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    254\u001B[0m             file_hash\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m253f8cb515780f3b799900260a226db6\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    255\u001B[0m         )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\data_utils.py:346\u001B[0m, in \u001B[0;36mget_file\u001B[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001B[0m\n\u001B[0;32m    344\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    345\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 346\u001B[0m         \u001B[43murlretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43morigin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDLProgbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    347\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39merror\u001B[38;5;241m.\u001B[39mHTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    348\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(error_msg\u001B[38;5;241m.\u001B[39mformat(origin, e\u001B[38;5;241m.\u001B[39mcode, e\u001B[38;5;241m.\u001B[39mmsg))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\data_utils.py:87\u001B[0m, in \u001B[0;36murlretrieve\u001B[1;34m(url, filename, reporthook, data)\u001B[0m\n\u001B[0;32m     85\u001B[0m response \u001B[38;5;241m=\u001B[39m urlopen(url, data)\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fd:\n\u001B[1;32m---> 87\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunk_read(response, reporthook\u001B[38;5;241m=\u001B[39mreporthook):\n\u001B[0;32m     88\u001B[0m         fd\u001B[38;5;241m.\u001B[39mwrite(chunk)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\data_utils.py:76\u001B[0m, in \u001B[0;36murlretrieve.<locals>.chunk_read\u001B[1;34m(response, chunk_size, reporthook)\u001B[0m\n\u001B[0;32m     74\u001B[0m count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m---> 76\u001B[0m     chunk \u001B[38;5;241m=\u001B[39m \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m     count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m reporthook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py:463\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    461\u001B[0m     \u001B[38;5;66;03m# Amount is given, implement using readinto\u001B[39;00m\n\u001B[0;32m    462\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mbytearray\u001B[39m(amt)\n\u001B[1;32m--> 463\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    464\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b)[:n]\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[0;32m    465\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    466\u001B[0m     \u001B[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001B[39;00m\n\u001B[0;32m    467\u001B[0m     \u001B[38;5;66;03m# and self.chunked\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py:507\u001B[0m, in \u001B[0;36mHTTPResponse.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    502\u001B[0m         b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmemoryview\u001B[39m(b)[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength]\n\u001B[0;32m    504\u001B[0m \u001B[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001B[39;00m\n\u001B[0;32m    505\u001B[0m \u001B[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001B[39;00m\n\u001B[0;32m    506\u001B[0m \u001B[38;5;66;03m# (for example, reading in 1k chunks)\u001B[39;00m\n\u001B[1;32m--> 507\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m n \u001B[38;5;129;01mand\u001B[39;00m b:\n\u001B[0;32m    509\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[0;32m    510\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[0;32m    511\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py:1241\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1238\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1239\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1240\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1242\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1243\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py:1099\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1097\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1098\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1099\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1100\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#call vgg model\n",
    "vgg_model =  VGG19(include_top=True , weights='imagenet')\n",
    "for models in vgg_model.layers:\n",
    "  models.trainable= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zjv1014c3Nf3"
   },
   "outputs": [],
   "source": [
    "#converting from functionally model to sequential model\n",
    "#removing the last 2 alyer to get rid of output layer in VGG16\n",
    "vgg_model = keras.Model(inputs=vgg_model.input, outputs=vgg_model.layers[-2].output)\n",
    "model = keras.Sequential()\n",
    "for layer in vgg_model.layers:\n",
    "  model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pU8A9H4Hfs6t"
   },
   "outputs": [],
   "source": [
    "#add trianbles layers\n",
    "model.add(Dense(4056, activation='relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer=\"adam\", loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjo6QDIZjlDU",
    "outputId": "e2828ba0-dfe7-4a23-b8f9-57625b6621d1"
   },
   "outputs": [],
   "source": [
    "train_data = defect_tree = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/content/drive/My Drive/archive_(1)/images',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/content/drive/My Drive/archive_(1)/images',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7WBbJ_JwFbL",
    "outputId": "7d18a585-1257-4eda-ac79-a5af37f4bf97"
   },
   "outputs": [],
   "source": [
    "batch_size =32\n",
    "model.fit(train_data,\n",
    "    validation_data = test_data, \n",
    "    callbacks=[early],\n",
    "    epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mDVRpUBtW0Q",
    "outputId": "4c6e07a2-097a-465a-9a13-5cb66c19bc5f"
   },
   "outputs": [],
   "source": [
    "#evulate mmodel\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4riSI652xwP"
   },
   "outputs": [],
   "source": [
    "#predict model\n",
    "y_pred = np.array([])\n",
    "y_true = np.array([])\n",
    "i = 0\n",
    "\n",
    "for image,label in test_data : \n",
    "  i+=1\n",
    "  y = model.predict(image)\n",
    "  y = np.argmax(y,axis=1)\n",
    "  y_true = np.append(y_true,label)\n",
    "  y_pred = np.append(y_pred,y)\n",
    "  if i == 176 // 32 + 1:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eygd26zldEfe",
    "outputId": "7529128f-8353-49f3-b57f-11cffc30b304"
   },
   "outputs": [],
   "source": [
    "from  sklearn .metrics import classification_report,confusion_matrix\n",
    "report=classification_report(y_true,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wO382FgmgHLy",
    "outputId": "d38bf322-10e3-424d-9555-1e0a88ef56ee"
   },
   "outputs": [],
   "source": [
    "cm= confusion_matrix(y_true,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiRE3ljPtGgj",
    "outputId": "c7be753b-15c2-4d49-c0f9-a511b6fd7eae"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn \n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [0,1]],\n",
    "                  columns = [i for i in [0,1]])\n",
    "seaborn .heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d')\n",
    "plt.title('confusion matrix')\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('Actual');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6kTE9bFtg2U"
   },
   "outputs": [],
   "source": [
    "model.save(\"textile.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
